{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "pd.options.display.max_columns=999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root\n",
    "folder = './2019/04/14/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aircraft\n",
    "Has the information about each tracked aircraft. Key metrics can be used:\n",
    "\n",
    "- **Id**: Aircraft ID\n",
    "- **AircraftModelId**: Model ID to **join `model` data**\n",
    "- **Blocked**: Whether the aircraft is blocked by the FAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircraft = pd.read_csv(folder + \"aircraft_20190414030057.csv\")\n",
    "aircraft = aircraft[[\"Id\", \"AircraftModelId\", \"Blocked\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Has the model information for each aircraft. Key metrics can be used:\n",
    "\n",
    "(`Crew` is not used here since it has value as large as 48,200, which is not a reasonable number for crew members of a flight)\n",
    "\n",
    "- **Id**: Can be used to join on **AircraftModelId** in `aircraft` table\n",
    "- **NormalCruiseSpeed**: Normal cruising speed for the aircraft model\n",
    "- **NormalRange**: Normal range for the aircraft model\n",
    "- **NormalPassengers**: Normal passengers for the aircraft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pd.read_csv(folder + \"model_20190414030057.csv\")\n",
    "model = model[[\"Id\", \"NormalCruiseSpeed\", \"NormalRange\", \"NormalPassengers\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ownership\n",
    "Has the information about the ownership for each tracked aircraft. Key metrics can be used:\n",
    "\n",
    "- **AircraftId**: Can be used to join on **Id** in `Aircraft` table\n",
    "- **CompanyId**: Can be used to join on **Id** in `Company` table\n",
    "- **OwnershipPercentage**: Ownership percentage held by the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ownership = pd.read_csv(folder + \"ownership_20190414030057.csv\")\n",
    "ownership = ownership[[\"AircraftId\", \"CompanyId\", \"OwnershipPercentage\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company\n",
    "\n",
    "Has the information about tracked companies. Key metrics can be used:\n",
    "- **Id**: Can be used to join on **CompanyId** in `Ownership` table\n",
    "- **Symbol**: Ticker if the company is public traded, otherwise is empty\n",
    "- **Industry or Sector**: Indicator of the company's industry or sector\n",
    "- **Latitude & Longitude**: Geo-coordinate\n",
    "- **Figi**: For mapping purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = pd.read_csv(folder + \"company_20190414030057.csv\")\n",
    "company = company[[\"Id\", \"Exchange\", \"Symbol\", \"Industry\", \"Sector\", \"Latitude\", \"Longitude\", \"Figi\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship\n",
    "Has the information about the relationship between two companies. Key metrics can be used:\n",
    "\n",
    "- **CompanyId**: Can be used to join on **Id** in `Company` table\n",
    "- **RelatedCompanyId**: Can be used to join on **Id** in `Company` table\n",
    "- **Type**: Type of relationship\n",
    "- **StartDate**: Beginning of the date range when the relationship was active\n",
    "- **EndDate**: End of the date range when the relationship was active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship = pd.read_csv(folder + \"relationships_20190414030057.csv\")\n",
    "relationship = relationship[[\"CompanyId\", \"RelatedCompanyId\", \"Type\", \"StartDate\", \"EndDate\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airport\n",
    "Has the information about the airports where aircrafts take of or land. Key metrics can be used:\n",
    "\n",
    "- **Icao**: The ICAO of the airport\n",
    "- **Classification**: filter out “closed” and use numerical value to show the data instead of categorical\n",
    "- **Latitude & Longitude**: Can be used to locate the airport and companies nearby\n",
    "- **Country**: Can be used to indicate overseas or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport = pd.read_csv(folder + \"airport_20190414030057.csv\")\n",
    "airport = airport[[\"Icao\", \"Classification\", \"Latitude\", \"Longitude\", \"Country\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight\n",
    "Has the information about flight hisotry on tracked aircrafts. Key metrics can be used:\n",
    "\n",
    "- **AircraftId**: Can be used to join on **Id** in `Aircraft` table\n",
    "- **DepartureTime & ArrivalTime**: Departure and arrival time\n",
    "- **DepartureIcao & ArrivalIcao**: Can be used to join on **ICao** in `airport` table\n",
    "- **StayDurationSeconds**: Length of the stay expressed in seconds (Crucial metrics for staying time. Based on the report from JetTrack, a short duration time (one or two hour) indicates a group was dropped off and picked up later. Therefore, the length of the duration could indicate more information than just a time period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = pd.read_csv(folder + \"flight_20190414030057.csv\", parse_dates=[\"DepartureTime\", \"ArrivalTime\"])\n",
    "flight = flight[[\"AircraftId\", \"DepartureTime\", \"DepartureIcao\", \"ArrivalTime\", \"ArrivalIcao\", \"StayDurationSeconds\"]].sort_values(\"DepartureTime\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactions\n",
    "Has the information about M&A transactions in different status/stages. Key metrics can be used:\n",
    "- **Id**: Can be used in filtering\n",
    "- **CompanyId1**: Can be used to join on **Id** in `Company` table\n",
    "- **CompanyId2**: Can be used to join on **Id** in `Company` table\n",
    "- **Status**: Include null, Rumor, Pending, Cancelled, and Complete\n",
    "- **RumorDate**: The date when the transaction is in Rumor stage\n",
    "- **CancelDate**: The date when the transaction is cancelled\n",
    "- **ClosingDate**: The date when the transaction is closed\n",
    "- **AnnouncementDate**: The date when the transaction is in Announcement stage\n",
    "- **TargetedClosingDate**: The date when the transaction is expected to be closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction = pd.read_csv(folder + \"transactions_20190414030057.csv\", parse_dates=[\"RumorDate\", \"CancelDate\", \"ClosingDate\", \"AnnouncementDate\", \"TargetedClosingDate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Aircraft: Change blocked values to 0 and 1\n",
    "aircraft.rename(columns={\"Id\": \"AircraftId\"}, inplace=True)\n",
    "aircraft[\"Blocked\"] = aircraft.apply(lambda x: 1 if x[\"Blocked\"] == True else (0 if x[\"Blocked\"] == False else np.nan), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Merge Aircraft with Model -> air_mod\n",
    "model.rename(columns={\"Id\": \"AircraftModelId\"}, inplace=True)\n",
    "air_mod = aircraft.merge(model, how=\"left\", on=[\"AircraftModelId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Merge air_mod with Ownership -> air_mod_own\n",
    "air_mod_own = air_mod.merge(ownership, how=\"left\", on=[\"AircraftId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Clean the companies\n",
    "# - Rename Id to CompanyId for future join\n",
    "company.rename(columns={\"Id\": \"CompanyId\"}, inplace=True)\n",
    "# - Drop companies without Latitude nor Longitude\n",
    "company = company[~((company[\"Latitude\"].isnull()) | (company[\"Longitude\"].isnull()))]\n",
    "# - Drop companies without Industry nor Sector\n",
    "company = company[~((company[\"Sector\"].isnull()) | (company[\"Industry\"].isnull()))]\n",
    "# - Drop companies without Symbol since it's impossible to map\n",
    "company = company[~company[\"Symbol\"].isnull()]\n",
    "# - Create Ticker = Exchange : Symbol to make each Ticker is unique\n",
    "company[\"Ticker\"] = company[\"Exchange\"] + \":\" + company[\"Symbol\"]\n",
    "# - Reorder the dataframe\n",
    "company = company[[\"CompanyId\", \"Ticker\", \"Sector\", \"Latitude\", \"Longitude\", \"Figi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Merge air_mod_own with company -> air_mod_own_comp\n",
    "air_mod_own_comp = air_mod_own.merge(company, how=\"left\", on=\"CompanyId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Map company to Relationship\n",
    "comp_rel = relationship.merge(company, how=\"left\", on=\"CompanyId\").merge(company, how=\"left\", left_on=\"RelatedCompanyId\", right_on=\"CompanyId\", suffixes=[\"_Source\", \"_Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Map Airport to Flight -> airport_flight\n",
    "airport_flight = flight.merge(airport, how=\"left\", left_on=\"DepartureIcao\", right_on=\"Icao\").merge(airport, how=\"left\", left_on=\"ArrivalIcao\", right_on=\"Icao\", suffixes=[\"_Departure\", \"_Arrival\"])\n",
    "del airport_flight[\"DepartureIcao\"]\n",
    "del airport_flight[\"ArrivalIcao\"]\n",
    "airport_flight[\"SameCountry\"] = airport_flight.apply(lambda x: 1 if x[\"Country_Departure\"] == x[\"Country_Arrival\"] else 0, axis=1)\n",
    "del airport_flight[\"Country_Departure\"]\n",
    "del airport_flight[\"Country_Arrival\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Use Latitude + Longitude + defined radius algo to find target companies within the distance range from the arrival airport\n",
    "#    then expand the flight records (if 5 companies are within the range, then that one flight records will be expanded into 5) -> new_flights\n",
    "RADIUS = 200\n",
    "COMP_DICT = company[[\"Ticker\", \"Longitude\", \"Latitude\"]].to_dict(\"records\")\n",
    "def comp_detct(lon_a, lat_a, lon_c, lat_c, radius):\n",
    "    \"\"\"\n",
    "    Calculate whether a company is whithin the range of an airport\n",
    "    for a given radius (in miles)\n",
    "    \"\"\"\n",
    "    lon_a, lat_a, lon_c, lat_c = map(np.radians, [lon_a, lat_a, lon_c, lat_c])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon_c - lon_a \n",
    "    dlat = lat_c - lat_a \n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat_a) * np.cos(lat_c) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 3959 # Radius of earth in miles\n",
    "    d = c * r\n",
    "    \n",
    "    if d <= radius: \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def master_detct(lon_a, lat_a):\n",
    "    comp_list = []\n",
    "    for value in COMP_DICT:\n",
    "        lon_c = value[\"Longitude\"]\n",
    "        lat_c = value[\"Latitude\"]\n",
    "        ticker = value[\"Ticker\"]\n",
    "        if comp_detct(lon_a, lat_a, lon_c, lat_c, RADIUS):\n",
    "            comp_list.append(ticker)            \n",
    "    return comp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concerns Raised\n",
    "- The above algorithm will go through each row in the `exp_airport_flight`\n",
    "- For each row, it will scan through all companies in the `COMP_DICT` to find companies within defined range (100 miles) from the arrival airport\n",
    "- For each row, it will take **232ms**. \n",
    "- To scan all rows in `exp_airport_flight`, it will take 1,879,522 * 232 / 1000 / 60 / 60 / 24 = **5 days**\n",
    "\n",
    "### Solutions\n",
    "1. Shrink the flight data based on certain range of depature date.\n",
    "    - Not applicable since length of the data where `DepartureTime >= '2019-01-01'` is 112,976, which will take 7 hours to finish\n",
    "2. **Shrink the flight data based on certain tickers.**\n",
    "    - Based on the transaction files, the firm has most transactions among the whole period are:\n",
    "        - Id=160 (11 transactions)\n",
    "        - Id=53151 (9 transactions)\n",
    "        - Id=133 (9 transactions)\n",
    "        - Id=4589 (8 transactions)\n",
    "    - Total flight records of above companies are 6,212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Merge exp_airport_flight with air_mod_own_comp for departure companies (and keep above companies only)\n",
    "airport_flight_dep_comp = airport_flight.merge(air_mod_own_comp, how=\"left\", on=\"AircraftId\")\n",
    "airport_flight_dep_comp = airport_flight_dep_comp[airport_flight_dep_comp[\"CompanyId\"].isin([160, 53151, 133, 4589])]\n",
    "cols = [\"Ticker\", \"Figi\", \"Sector\", \"DepartureTime\", \"Classification_Departure\"] + \\\n",
    "       [c for c in airport_flight_dep_comp.columns if \"Normal\" in c] + [\"OwnershipPercentage\", \"Blocked\"] + \\\n",
    "       [\"ArrivalTime\", \"Latitude_Arrival\", \"Longitude_Arrival\", \"Classification_Arrival\"] + \\\n",
    "       [\"SameCountry\", \"StayDurationSeconds\"]\n",
    "exp_airport_flight_dep_comp = airport_flight_dep_comp[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 10s, sys: 2.34 s, total: 21min 12s\n",
      "Wall time: 21min 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 9. Use Latitude + Longitude + defined radius algo to find target companies within the distance range from the arrival airport\n",
    "# will roughly take 20 mins\n",
    "exp_airport_flight_dep_comp[\"PotentialCompanies\"] = exp_airport_flight_dep_comp.apply(lambda x: master_detct(x[\"Longitude_Arrival\"], x[\"Latitude_Arrival\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further filtering: over 800,000 negative StayDurationSeconds\n",
    "exp_airport_flight_dep_comp = exp_airport_flight_dep_comp[exp_airport_flight_dep_comp[\"StayDurationSeconds\"] > 0].reset_index(drop=True)\n",
    "\n",
    "# Unnest PotentialCompanies for each flight record\n",
    "unnest = pd.DataFrame({\"PotentialCompanies\":np.concatenate(exp_airport_flight_dep_comp.PotentialCompanies.values)},index=exp_airport_flight_dep_comp.index.repeat(exp_airport_flight_dep_comp.PotentialCompanies.str.len()))\n",
    "new_flights = unnest.join(exp_airport_flight_dep_comp.drop(\"PotentialCompanies\",1), how=\"left\")\n",
    "new_flights = new_flights[list(new_flights.columns)[1:] + [\"PotentialCompanies\"]]\n",
    "new_flights.rename(columns={\"PotentialCompanies\": \"TargetCompany\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Merge new_flights with company for arrival company\n",
    "final_new_flights = new_flights.merge(company, how=\"left\", left_on=\"TargetCompany\", right_on=\"Ticker\", suffixes=[\"_Source\", \"_Target\"])\n",
    "final_new_flights.drop([\"TargetCompany\", \"CompanyId\", \"Latitude\", \"Longitude\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Map `Relationship` to `new_flights` -> `final_features`\n",
    "cols = [\"Ticker_Source\", \"Ticker_Target\", \"Type\", \"StartDate\", \"EndDate\"]\n",
    "rel = comp_rel[cols]\n",
    "final_features = final_new_flights.merge(rel, how=\"left\", on=[\"Ticker_Source\", \"Ticker_Target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- The `fianl_features` has 6,846,694 records \n",
    "- Only 10,422 of them have relationship\n",
    "- The rate of that is very small, so make the `final_features = final_new_flights` at the step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = final_new_flights.copy()\n",
    "\n",
    "# Further cleaning\n",
    "# Remove latitude and longitude of the arrival airports\n",
    "final_features.drop([\"Latitude_Arrival\", \"Longitude_Arrival\"], axis=1, inplace=True)\n",
    "# Remove the records where Ticker_Source == Ticker_Target\n",
    "final_features = final_features.query(\"Ticker_Source != Ticker_Target\")\n",
    "# Remove the records where Ticker_Source is null\n",
    "final_features = final_features[~final_features[\"Ticker_Source\"].isnull()]\n",
    "# Remove the records where Ticker_Target is null\n",
    "final_features = final_features[~final_features[\"Ticker_Target\"].isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove TargetedClosingDate since it's not meaningful in terms of defining Status\n",
    "# 2. Remove CancelDate since there are no values\n",
    "updated_transaction = transaction.drop([\"TargetedClosingDate\", \"CancelDate\"], axis=1)\n",
    "\n",
    "# 3. Remove all records where Status == Cancelled since there are no CancelDate for all Cancelled records\n",
    "updated_transaction = updated_transaction[updated_transaction[\"Status\"] != \"Cancelled\"]\n",
    "\n",
    "# 4. Remove all records where Status == null\n",
    "updated_transaction = updated_transaction[~updated_transaction[\"Status\"].isnull()]\n",
    "\n",
    "# 5. Keep the records where Status == Rumor.\n",
    "\"\"\"\n",
    "- Reason: Might be some insights even thought that is only a rumor\n",
    "- Notes: \n",
    "    - Rumor has the same `RumorDate` and `AnnoucementDate`\n",
    "    - Didn't observe the `Rumor Cancelled` status, so will assume `Rumor` will last forever\n",
    "- Remove `Id = 6316`\n",
    "\"\"\"\n",
    "updated_transaction = updated_transaction[updated_transaction[\"Id\"] != 6316]\n",
    "\n",
    "# 6. Filter the data down to CompanyId1 in (160, 53151, 133, 4589)\n",
    "updated_transaction = updated_transaction.query(\"CompanyId1 in [160, 53151, 133, 4589]\")\n",
    "\n",
    "# 7. Check if there are duplicated records of the combination of (CompanyId1, CompanyId2)\n",
    "len(updated_transaction.groupby([\"CompanyId1\", \"CompanyId2\"]).size().reset_index().rename(columns={0: \"count\"}).query(\"count != 1\")) == 0\n",
    "\n",
    "# 8. Merge transaction data with company info\n",
    "tran_comp = updated_transaction.merge(company[[\"CompanyId\", \"Ticker\"]], how=\"left\", left_on=\"CompanyId1\", right_on=\"CompanyId\").merge(company[[\"CompanyId\", \"Ticker\"]], how=\"left\", left_on=\"CompanyId2\", right_on=\"CompanyId\", suffixes=[\"_Source\", \"_Target\"])\n",
    "tran_comp = tran_comp[[\"Ticker_Source\", \"Ticker_Target\", \"Status\", \"RumorDate\", \"AnnouncementDate\", \"ClosingDate\"]]\n",
    "\n",
    "# 9. Filter out non-public companies\n",
    "tran_comp = tran_comp[~tran_comp[\"Ticker_Source\"].isnull()]\n",
    "tran_comp = tran_comp[~tran_comp[\"Ticker_Target\"].isnull()]\n",
    "\n",
    "# 10. Remove records where Status == \"Complete\" but ClosingDate is null\n",
    "tran_comp[\"Remove\"] = tran_comp.apply(lambda x: 1 if (x[\"Status\"] == \"Complete\" and str(x[\"ClosingDate\"]) == 'NaT') else 0, axis=1)\n",
    "tran_comp = tran_comp[tran_comp[\"Remove\"] == 0].reset_index(drop=True)\n",
    "del tran_comp[\"Remove\"]\n",
    "\n",
    "# 11. Merge feature with targets\n",
    "final_df = final_features.merge(tran_comp, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_match(x):\n",
    "    \"\"\"\n",
    "    Find the right status based on the arrival time\n",
    "    \"\"\"\n",
    "    if str(x[\"Status\"]) == \"nan\":\n",
    "        return \"Nothing\"\n",
    "    elif str(x[\"Status\"]) == \"Rumor\":\n",
    "        if x[\"ArrivalTime\"] < x[\"RumorDate\"]:\n",
    "            return \"Nothing\"\n",
    "        else:\n",
    "            return \"Rumor\"\n",
    "    elif str(x[\"Status\"]) == \"Pending\":\n",
    "        if str(x[\"RumorDate\"]) != 'NaT' and x[\"ArrivalTime\"] < x[\"RumorDate\"]:\n",
    "            return \"Nothing\"\n",
    "        elif str(x[\"RumorDate\"]) != 'NaT' and x[\"ArrivalTime\"] >= x[\"RumorDate\"] and x[\"ArrivalTime\"] < x[\"AnnouncementDate\"]:\n",
    "            return \"Rumor\"\n",
    "        elif x[\"ArrivalTime\"] >= x[\"AnnouncementDate\"]:\n",
    "            return \"Pending\"\n",
    "    elif str(x[\"Status\"]) == \"Complete\":\n",
    "        if str(x[\"RumorDate\"]) != 'NaT' and x[\"ArrivalTime\"] < x[\"RumorDate\"]:\n",
    "            return \"Nothing\"\n",
    "        elif str(x[\"RumorDate\"]) != 'NaT' and x[\"ArrivalTime\"] >= x[\"RumorDate\"] and x[\"ArrivalTime\"] < x[\"AnnouncementDate\"]:\n",
    "            return \"Rumor\"\n",
    "        elif x[\"ArrivalTime\"] >= x[\"AnnouncementDate\"] and x[\"ArrivalTime\"] < x[\"ClosingDate\"]:\n",
    "            return \"Pending\"\n",
    "        elif x[\"ArrivalTime\"] >= x[\"ClosingDate\"]:\n",
    "            return \"Complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 5.09 s, total: 1min 47s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 12. define the new status based on the time\n",
    "final_df[\"NewStatus\"] = final_df.apply(lambda x: status_match(x), axis=1)\n",
    "final_df.drop([\"Status\", \"RumorDate\", \"AnnouncementDate\", \"ClosingDate\"], axis=1, inplace=True)\n",
    "final_df = final_df.sort_values([\"DepartureTime\", \"Ticker_Source\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker_Source</th>\n",
       "      <th>Figi_Source</th>\n",
       "      <th>Sector_Source</th>\n",
       "      <th>DepartureTime</th>\n",
       "      <th>Classification_Departure</th>\n",
       "      <th>NormalCruiseSpeed</th>\n",
       "      <th>NormalRange</th>\n",
       "      <th>NormalPassengers</th>\n",
       "      <th>OwnershipPercentage</th>\n",
       "      <th>Blocked</th>\n",
       "      <th>ArrivalTime</th>\n",
       "      <th>Classification_Arrival</th>\n",
       "      <th>SameCountry</th>\n",
       "      <th>StayDurationSeconds</th>\n",
       "      <th>Ticker_Target</th>\n",
       "      <th>Sector_Target</th>\n",
       "      <th>Figi_Target</th>\n",
       "      <th>NewStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYS:BSX</td>\n",
       "      <td>BBG000C0LY07</td>\n",
       "      <td>Health Technology</td>\n",
       "      <td>2007-01-01 13:47:00</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>488.0</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-01-01 14:15:24</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>1</td>\n",
       "      <td>104676.0</td>\n",
       "      <td>NYS:MD</td>\n",
       "      <td>Health Services</td>\n",
       "      <td>BBG000H8LJM4</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYS:BSX</td>\n",
       "      <td>BBG000C0LY07</td>\n",
       "      <td>Health Technology</td>\n",
       "      <td>2007-01-01 13:47:00</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>488.0</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-01-01 14:15:24</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>1</td>\n",
       "      <td>104676.0</td>\n",
       "      <td>NYS:NEE</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>BBG000BJSF01</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NYS:BSX</td>\n",
       "      <td>BBG000C0LY07</td>\n",
       "      <td>Health Technology</td>\n",
       "      <td>2007-01-01 13:47:00</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>488.0</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-01-01 14:15:24</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>1</td>\n",
       "      <td>104676.0</td>\n",
       "      <td>NYS:CCL</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>BBG000BF6PR2</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NYS:BSX</td>\n",
       "      <td>BBG000C0LY07</td>\n",
       "      <td>Health Technology</td>\n",
       "      <td>2007-01-01 13:47:00</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>488.0</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-01-01 14:15:24</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>1</td>\n",
       "      <td>104676.0</td>\n",
       "      <td>NAS:CTXS</td>\n",
       "      <td>Technology Services</td>\n",
       "      <td>BBG000FQ9611</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYS:BSX</td>\n",
       "      <td>BBG000C0LY07</td>\n",
       "      <td>Health Technology</td>\n",
       "      <td>2007-01-01 13:47:00</td>\n",
       "      <td>large_airport</td>\n",
       "      <td>488.0</td>\n",
       "      <td>5940.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-01-01 14:15:24</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>1</td>\n",
       "      <td>104676.0</td>\n",
       "      <td>NYS:JBL</td>\n",
       "      <td>Electronic Technology</td>\n",
       "      <td>BBG000BJNJ80</td>\n",
       "      <td>Nothing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker_Source   Figi_Source      Sector_Source       DepartureTime  \\\n",
       "0       NYS:BSX  BBG000C0LY07  Health Technology 2007-01-01 13:47:00   \n",
       "1       NYS:BSX  BBG000C0LY07  Health Technology 2007-01-01 13:47:00   \n",
       "2       NYS:BSX  BBG000C0LY07  Health Technology 2007-01-01 13:47:00   \n",
       "3       NYS:BSX  BBG000C0LY07  Health Technology 2007-01-01 13:47:00   \n",
       "4       NYS:BSX  BBG000C0LY07  Health Technology 2007-01-01 13:47:00   \n",
       "\n",
       "  Classification_Departure  NormalCruiseSpeed  NormalRange  NormalPassengers  \\\n",
       "0            large_airport              488.0       5940.0              13.0   \n",
       "1            large_airport              488.0       5940.0              13.0   \n",
       "2            large_airport              488.0       5940.0              13.0   \n",
       "3            large_airport              488.0       5940.0              13.0   \n",
       "4            large_airport              488.0       5940.0              13.0   \n",
       "\n",
       "   OwnershipPercentage  Blocked         ArrivalTime Classification_Arrival  \\\n",
       "0                100.0      1.0 2007-01-01 14:15:24          small_airport   \n",
       "1                100.0      1.0 2007-01-01 14:15:24          small_airport   \n",
       "2                100.0      1.0 2007-01-01 14:15:24          small_airport   \n",
       "3                100.0      1.0 2007-01-01 14:15:24          small_airport   \n",
       "4                100.0      1.0 2007-01-01 14:15:24          small_airport   \n",
       "\n",
       "   SameCountry  StayDurationSeconds Ticker_Target          Sector_Target  \\\n",
       "0            1             104676.0        NYS:MD        Health Services   \n",
       "1            1             104676.0       NYS:NEE              Utilities   \n",
       "2            1             104676.0       NYS:CCL      Consumer Services   \n",
       "3            1             104676.0      NAS:CTXS    Technology Services   \n",
       "4            1             104676.0       NYS:JBL  Electronic Technology   \n",
       "\n",
       "    Figi_Target NewStatus  \n",
       "0  BBG000H8LJM4   Nothing  \n",
       "1  BBG000BJSF01   Nothing  \n",
       "2  BBG000BF6PR2   Nothing  \n",
       "3  BBG000FQ9611   Nothing  \n",
       "4  BBG000BJNJ80   Nothing  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"jettrack.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remained Concerns & Thoughts\n",
    "\n",
    "1. The `final_df` has 6,839,339 records after using `radius` = 100 miles. Amongst them, only 186 records have NewStatus (target) as non \"Nothing\".\n",
    "2. We can combine the flight data with our merge/acquisition signal data, where we could first spot the merge/acquisition signal and then look at the associated flight data in a relative time range.\n",
    "3. If we are using longitude and latitude to detect the potential associated companies within a certain radius of the arrival airport, we can use machine learning to detect the optimal radius.\n",
    "4. Regarding setting radius, we have the following concerns. Consider the two scenarios:\n",
    "    - When a large-size company, like Amazon, flies to a large city, like New York, it is extremely hard to know what Amazon is up to in New York, given the fact that NYC is a big city and there are way too many possibilities that it becomes unreasonable to predict the company’s traveling purposes. In addition, there are a lot of companies’ headquarters locating in big city, like New York. Therefore, for a flight that Amazon takes to NYC, we can get over thousands of companies based on our current model.\n",
    "    - On the other hand, it is unusual for a large-size company, like Amazon, to flies to a relatively smaller city, like Austin. In such case, it is easier and more reasonable for us to predict what Amazon is up to in Austin. Given the fact that there aren’t too many companies setting their headquarter in Austin, we can get a shorter list of targeting companies based on our current model, and such flight information may be more valuable than the ones about Amazon flying to NYC.\n",
    "5. After discussion with Joschi, a reasonable radius could be 4-hr driving distance from the arrival airport, which is 80 miles/hour * 4 hrs = 320 miles. However, 320 miles is pretty large, 200 miles is more reasonable as the radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
