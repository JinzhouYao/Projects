{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "pd.options.display.max_columns=999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root\n",
    "folder = './2019/04/14/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aircraft\n",
    "Has the information about each tracked aircraft. Key metrics can be used:\n",
    "\n",
    "- **Id**: Aircraft ID\n",
    "- **AircraftModelId**: Model ID to **join `model` data**\n",
    "- **Blocked**: Whether the aircraft is blocked by the FAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aircraft = pd.read_csv(folder + \"aircraft_20190414030057.csv\")\n",
    "aircraft = aircraft[[\"Id\", \"AircraftModelId\", \"Blocked\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Has the model information for each aircraft. Key metrics can be used:\n",
    "\n",
    "(`Crew` is not used here since it has value as large as 48,200, which is not a reasonable number for crew members of a flight)\n",
    "\n",
    "- **Id**: Can be used to join on **AircraftModelId** in `aircraft` table\n",
    "- **NormalCruiseSpeed**: Normal cruising speed for the aircraft model\n",
    "- **NormalRange**: Normal range for the aircraft model\n",
    "- **NormalPassengers**: Normal passengers for the aircraft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pd.read_csv(folder + \"model_20190414030057.csv\")\n",
    "model = model[[\"Id\", \"NormalCruiseSpeed\", \"NormalRange\", \"NormalPassengers\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ownership\n",
    "Has the information about the ownership for each tracked aircraft. Key metrics can be used:\n",
    "\n",
    "- **AircraftId**: Can be used to join on **Id** in `Aircraft` table\n",
    "- **CompanyId**: Can be used to join on **Id** in `Company` table\n",
    "- **OwnershipPercentage**: Ownership percentage held by the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ownership = pd.read_csv(folder + \"ownership_20190414030057.csv\")\n",
    "ownership = ownership[[\"AircraftId\", \"CompanyId\", \"OwnershipPercentage\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Company\n",
    "\n",
    "Has the information about tracked companies. Key metrics can be used:\n",
    "- **Id**: Can be used to join on **CompanyId** in `Ownership` table\n",
    "- **Symbol**: Ticker if the company is public traded, otherwise is empty\n",
    "- **Industry or Sector**: Indicator of the company's industry or sector\n",
    "- **Latitude & Longitude**: Geo-coordinate\n",
    "- **Figi**: For mapping purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = pd.read_csv(folder + \"company_20190414030057.csv\")\n",
    "company = company[[\"Id\", \"Exchange\", \"Symbol\", \"Industry\", \"Sector\", \"Latitude\", \"Longitude\", \"Figi\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship\n",
    "Has the information about the relationship between two companies. Key metrics can be used:\n",
    "\n",
    "- **CompanyId**: Can be used to join on **Id** in `Company` table\n",
    "- **RelatedCompanyId**: Can be used to join on **Id** in `Company` table\n",
    "- **Type**: Type of relationship\n",
    "- **StartDate**: Beginning of the date range when the relationship was active\n",
    "- **EndDate**: End of the date range when the relationship was active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship = pd.read_csv(folder + \"relationships_20190414030057.csv\")\n",
    "relationship = relationship[[\"CompanyId\", \"RelatedCompanyId\", \"Type\", \"StartDate\", \"EndDate\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airport\n",
    "Has the information about the airports where aircrafts take of or land. Key metrics can be used:\n",
    "\n",
    "- **Icao**: The ICAO of the airport\n",
    "- **Classification**: filter out “closed” and use numerical value to show the data instead of categorical\n",
    "- **Latitude & Longitude**: Can be used to locate the airport and companies nearby\n",
    "- **Country**: Can be used to indicate overseas or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport = pd.read_csv(folder + \"airport_20190414030057.csv\")\n",
    "airport = airport[[\"Icao\", \"Classification\", \"Latitude\", \"Longitude\", \"Country\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flight\n",
    "Has the information about flight hisotry on tracked aircrafts. Key metrics can be used:\n",
    "\n",
    "- **AircraftId**: Can be used to join on **Id** in `Aircraft` table\n",
    "- **DepartureTime & ArrivalTime**: Departure and arrival time\n",
    "- **DepartureIcao & ArrivalIcao**: Can be used to join on **ICao** in `airport` table\n",
    "- **StayDurationSeconds**: Length of the stay expressed in seconds (Crucial metrics for staying time. Based on the report from JetTrack, a short duration time (one or two hour) indicates a group was dropped off and picked up later. Therefore, the length of the duration could indicate more information than just a time period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight = pd.read_csv(folder + \"flight_20190414030057.csv\", parse_dates=[\"DepartureTime\", \"ArrivalTime\"])\n",
    "flight = flight[[\"AircraftId\", \"DepartureTime\", \"DepartureIcao\", \"ArrivalTime\", \"ArrivalIcao\", \"StayDurationSeconds\"]].sort_values(\"DepartureTime\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transactions\n",
    "Has the information about M&A transactions in different status/stages. Key metrics can be used:\n",
    "- **Id**: Can be used in filtering\n",
    "- **CompanyId1**: Can be used to join on **Id** in `Company` table\n",
    "- **CompanyId2**: Can be used to join on **Id** in `Company` table\n",
    "- **Status**: Include null, Rumor, Pending, Cancelled, and Complete\n",
    "- **RumorDate**: The date when the transaction is in Rumor stage\n",
    "- **CancelDate**: The date when the transaction is cancelled\n",
    "- **ClosingDate**: The date when the transaction is closed\n",
    "- **AnnouncementDate**: The date when the transaction is in Announcement stage\n",
    "- **TargetedClosingDate**: The date when the transaction is expected to be closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction = pd.read_csv(folder + \"transactions_20190414030057.csv\", parse_dates=[\"RumorDate\", \"CancelDate\", \"ClosingDate\", \"AnnouncementDate\", \"TargetedClosingDate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Aircraft: Change blocked values to 0 and 1\n",
    "aircraft.rename(columns={\"Id\": \"AircraftId\"}, inplace=True)\n",
    "aircraft[\"Blocked\"] = aircraft.apply(lambda x: 1 if x[\"Blocked\"] == True else (0 if x[\"Blocked\"] == False else np.nan), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Merge Aircraft with Model -> air_mod\n",
    "model.rename(columns={\"Id\": \"AircraftModelId\"}, inplace=True)\n",
    "air_mod = aircraft.merge(model, how=\"left\", on=[\"AircraftModelId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Merge air_mod with Ownership -> air_mod_own\n",
    "air_mod_own = air_mod.merge(ownership, how=\"left\", on=[\"AircraftId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Clean the companies\n",
    "# - Rename Id to CompanyId for future join\n",
    "company.rename(columns={\"Id\": \"CompanyId\"}, inplace=True)\n",
    "# - Drop companies without Latitude nor Longitude\n",
    "company = company[~((company[\"Latitude\"].isnull()) | (company[\"Longitude\"].isnull()))]\n",
    "# - Drop companies without Industry nor Sector\n",
    "company = company[~((company[\"Sector\"].isnull()) | (company[\"Industry\"].isnull()))]\n",
    "# - Drop companies without Symbol since it's impossible to map\n",
    "company = company[~company[\"Symbol\"].isnull()]\n",
    "# - Create Ticker = Exchange : Symbol to make each Ticker is unique\n",
    "company[\"Ticker\"] = company[\"Exchange\"] + \":\" + company[\"Symbol\"]\n",
    "# - Reorder the dataframe\n",
    "company = company[[\"CompanyId\", \"Ticker\", \"Sector\", \"Industry\", \"Latitude\", \"Longitude\", \"Figi\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Merge air_mod_own with company -> air_mod_own_comp\n",
    "air_mod_own_comp = air_mod_own.merge(company, how=\"left\", on=\"CompanyId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Map company to Relationship\n",
    "comp_rel = relationship.merge(company, how=\"left\", on=\"CompanyId\").merge(company, how=\"left\", left_on=\"RelatedCompanyId\", right_on=\"CompanyId\", suffixes=[\"_Source\", \"_Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Map Airport to Flight -> airport_flight\n",
    "airport_flight = flight.merge(airport, how=\"left\", left_on=\"DepartureIcao\", right_on=\"Icao\").merge(airport, how=\"left\", left_on=\"ArrivalIcao\", right_on=\"Icao\", suffixes=[\"_Departure\", \"_Arrival\"])\n",
    "del airport_flight[\"DepartureIcao\"]\n",
    "del airport_flight[\"ArrivalIcao\"]\n",
    "airport_flight[\"SameCountry\"] = airport_flight.apply(lambda x: 1 if x[\"Country_Departure\"] == x[\"Country_Arrival\"] else 0, axis=1)\n",
    "del airport_flight[\"Country_Departure\"]\n",
    "del airport_flight[\"Country_Arrival\"]\n",
    "\n",
    "# Remove negative StayDurationSeconds\n",
    "airport_flight = airport_flight[airport_flight[\"StayDurationSeconds\"] > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove TargetedClosingDate since it's not meaningful in terms of defining Status\n",
    "# 2. Remove CancelDate since there are no values\n",
    "updated_transaction = transaction.drop([\"TargetedClosingDate\", \"CancelDate\"], axis=1)\n",
    "\n",
    "# 3. Remove all records where Status == Cancelled since there are no CancelDate for all Cancelled records\n",
    "updated_transaction = updated_transaction[updated_transaction[\"Status\"] != \"Cancelled\"]\n",
    "\n",
    "# 4. Remove all records where Status == null\n",
    "updated_transaction = updated_transaction[~updated_transaction[\"Status\"].isnull()]\n",
    "\n",
    "# 5. Keep the records where Status == Rumor.\n",
    "\"\"\"\n",
    "- Reason: Might be some insights even thought that is only a rumor\n",
    "- Notes: \n",
    "    - Rumor has the same `RumorDate` and `AnnoucementDate`\n",
    "    - Didn't observe the `Rumor Cancelled` status, so will assume `Rumor` will last forever\n",
    "- Remove `Id = 6316`\n",
    "\"\"\"\n",
    "updated_transaction = updated_transaction[updated_transaction[\"Id\"] != 6316]\n",
    "\n",
    "# 7. Check if there are duplicated records of the combination of (CompanyId1, CompanyId2)\n",
    "len(updated_transaction.groupby([\"CompanyId1\", \"CompanyId2\"]).size().reset_index().rename(columns={0: \"count\"}).query(\"count != 1\")) == 0\n",
    "\n",
    "# 8. There are many transactions where company_1 and company_2 are not in the company table. Filter them out\n",
    "updated_transaction = updated_transaction[(updated_transaction[\"CompanyId1\"].isin(company[\"CompanyId\"].unique()) & updated_transaction[\"CompanyId2\"].isin(company[\"CompanyId\"].unique()))]\n",
    "\n",
    "updated_transaction = updated_transaction.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Merge exp_airport_flight with air_mod_own_comp for departure companies (and keep above companies only)\n",
    "airport_flight_dep_comp = airport_flight.merge(air_mod_own_comp, how=\"left\", on=\"AircraftId\")\n",
    "cols = [\"CompanyId\", \"Ticker\", \"Figi\", \"Sector\", \"Industry\", \"DepartureTime\", \"Classification_Departure\"] + \\\n",
    "       [c for c in airport_flight_dep_comp.columns if \"Normal\" in c] + [\"OwnershipPercentage\", \"Blocked\"] + \\\n",
    "       [\"ArrivalTime\", \"Latitude_Arrival\", \"Longitude_Arrival\", \"Classification_Arrival\"] + \\\n",
    "       [\"SameCountry\", \"StayDurationSeconds\"]\n",
    "exp_airport_flight_dep_comp = airport_flight_dep_comp[cols]\n",
    "\n",
    "# Further cleaning\n",
    "exp_airport_flight_dep_comp = exp_airport_flight_dep_comp[~exp_airport_flight_dep_comp[\"Ticker\"].isnull()]\n",
    "exp_airport_flight_dep_comp = exp_airport_flight_dep_comp[~((exp_airport_flight_dep_comp[\"Latitude_Arrival\"].isnull()) | (exp_airport_flight_dep_comp[\"Longitude_Arrival\"].isnull()))]\n",
    "\n",
    "# Narrow flight records down to companies in the transaction file\n",
    "transaction_comp = list(set(updated_transaction[\"CompanyId1\"]) | set(updated_transaction[\"CompanyId2\"]))\n",
    "narrowed_flights = exp_airport_flight_dep_comp[exp_airport_flight_dep_comp[\"CompanyId\"].isin(transaction_comp)]\n",
    "\n",
    "# The earliest date in the transaction file is 2009-08-31. Keep records after 2009\n",
    "narrowed_flights = narrowed_flights.query(\"ArrivalTime > '2009-01-01'\")\n",
    "\n",
    "# Remove outliers\n",
    "narrowed_flights = narrowed_flights.query(\"DepartureTime < ArrivalTime\")\n",
    "narrowed_flights = narrowed_flights.sort_values(\"ArrivalTime\").reset_index(drop=True).reset_index().rename(columns={\"index\": \"flight_id\"})\n",
    "\n",
    "narrowed_flights[\"TransactionId\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS = 100\n",
    "def distance(lon_a, lat_a, lon_c, lat_c, radius):\n",
    "    \"\"\"\n",
    "    Calculate whether a company is whithin the range of an airport\n",
    "    for a given radius (in miles)\n",
    "    \"\"\"\n",
    "    lon_a, lat_a, lon_c, lat_c = map(np.radians, [lon_a, lat_a, lon_c, lat_c])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon_c - lon_a \n",
    "    dlat = lat_c - lat_a \n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat_a) * np.cos(lat_c) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 3959 # Radius of earth in miles\n",
    "    d = c * r\n",
    "    \n",
    "    if d <= radius: \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 15s, sys: 11.1 s, total: 12min 26s\n",
      "Wall time: 12min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "Based on the transaction records to find qualified flight records\n",
    "\"\"\"\n",
    "for i in range(len(updated_transaction)):\n",
    "    comp_id_1 = updated_transaction.iloc[i][\"CompanyId1\"]\n",
    "    comp_id_2 = updated_transaction.iloc[i][\"CompanyId2\"]\n",
    "    tran_id = updated_transaction.iloc[i][\"Id\"]\n",
    "    coords_1 = list(company.query(\"CompanyId == @comp_id_1\")[[\"Longitude\", \"Latitude\"]].values[0])\n",
    "    coords_2 = list(company.query(\"CompanyId == @comp_id_2\")[[\"Longitude\", \"Latitude\"]].values[0])\n",
    "    df = narrowed_flights.query(\"CompanyId == @comp_id_1\")\n",
    "    if len(df) != 0:\n",
    "        for j in df.flight_id.unique():\n",
    "            coords_arrival = list(df.loc[j][[\"Longitude_Arrival\", \"Latitude_Arrival\"]].values)\n",
    "            if distance(coords_arrival[0], coords_arrival[1], coords_2[0], coords_2[1], RADIUS):\n",
    "                narrowed_flights.loc[j, \"TransactionId\"] = tran_id\n",
    "    df = narrowed_flights.query(\"CompanyId == @comp_id_2\")\n",
    "    if len(df) != 0:\n",
    "        for j in df.flight_id.unique():\n",
    "            coords_arrival = list(df.loc[j][[\"Longitude_Arrival\", \"Latitude_Arrival\"]].values)\n",
    "            if distance(coords_arrival[0], coords_arrival[1], coords_1[0], coords_1[1], RADIUS):\n",
    "                narrowed_flights.loc[j, \"TransactionId\"] = tran_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_flights = narrowed_flights.query(\"TransactionId != 0\")\n",
    "\n",
    "# 9. Merge new_flights with company for arrival company\n",
    "final_new_flights = new_flights.merge(updated_transaction[[\"Id\", \"CompanyId2\"]], how=\"left\", left_on=\"TransactionId\", right_on=\"Id\").merge(company, how=\"left\", left_on=\"CompanyId2\", right_on=\"CompanyId\", suffixes=[\"_Source\", \"_Target\"])\n",
    "final_new_flights.drop([\"flight_id\", \"CompanyId_Source\", \"Latitude_Arrival\", \"Longitude_Arrival\", \"TransactionId\", \n",
    "                        \"Id\", \"CompanyId2\", \"CompanyId_Target\", \"Latitude\", \"Longitude\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Map `Relationship` to `new_flights` -> `final_features`\n",
    "cols = [\"Ticker_Source\", \"Ticker_Target\", \"Type\", \"StartDate\", \"EndDate\"]\n",
    "rel = comp_rel[cols]\n",
    "final_features = final_new_flights.merge(rel, how=\"left\", on=[\"Ticker_Source\", \"Ticker_Target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- The `fianl_features` has 71,254 records \n",
    "- Only 6692 of them have relationship\n",
    "- The rate of that is very small, so make the `final_features = final_new_flights` at the step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = final_new_flights.copy()\n",
    "\n",
    "# Further cleaning\n",
    "# Remove the records where Ticker_Source == Ticker_Target\n",
    "final_features = final_features.query(\"Ticker_Source != Ticker_Target\")\n",
    "# Remove the records where Ticker_Source is null\n",
    "final_features = final_features[~final_features[\"Ticker_Source\"].isnull()]\n",
    "# Remove the records where Ticker_Target is null\n",
    "final_features = final_features[~final_features[\"Ticker_Target\"].isnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Targets Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Merge transaction data with company info\n",
    "tran_comp = updated_transaction.merge(company[[\"CompanyId\", \"Ticker\"]], how=\"left\", left_on=\"CompanyId1\", right_on=\"CompanyId\").merge(company[[\"CompanyId\", \"Ticker\"]], how=\"left\", left_on=\"CompanyId2\", right_on=\"CompanyId\", suffixes=[\"_Source\", \"_Target\"])\n",
    "tran_comp = tran_comp[[\"Ticker_Source\", \"Ticker_Target\", \"Status\", \"RumorDate\", \"AnnouncementDate\", \"ClosingDate\"]]\n",
    "\n",
    "# 9. Filter out non-public companies\n",
    "tran_comp = tran_comp[~tran_comp[\"Ticker_Source\"].isnull()]\n",
    "tran_comp = tran_comp[~tran_comp[\"Ticker_Target\"].isnull()]\n",
    "\n",
    "# 10. Remove records where Status == \"Complete\" but ClosingDate is null\n",
    "tran_comp[\"Remove\"] = tran_comp.apply(lambda x: 1 if (x[\"Status\"] == \"Complete\" and str(x[\"ClosingDate\"]) == 'NaT') else 0, axis=1)\n",
    "tran_comp = tran_comp[tran_comp[\"Remove\"] == 0].reset_index(drop=True)\n",
    "del tran_comp[\"Remove\"]\n",
    "\n",
    "# 11. Merge feature with targets\n",
    "final_df = final_features.merge(tran_comp, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_match(x):\n",
    "    \"\"\"\n",
    "    Find the right status based on the arrival time\n",
    "    \"\"\"\n",
    "    if str(x[\"Status\"]) == \"nan\":\n",
    "        return \"Nothing\"\n",
    "    elif str(x[\"Status\"]) == \"Rumor\":\n",
    "        if x[\"ArrivalTime\"] < x[\"RumorDate\"]:\n",
    "            return \"Nothing\"\n",
    "        else:\n",
    "            return \"Rumor\"\n",
    "    elif str(x[\"Status\"]) == \"Pending\":\n",
    "        if str(x[\"RumorDate\"]) != 'NaT' and x[\"ArrivalTime\"] >= x[\"RumorDate\"] and x[\"ArrivalTime\"] < x[\"AnnouncementDate\"]:\n",
    "            return \"Rumor\"\n",
    "        elif x[\"ArrivalTime\"] >= x[\"AnnouncementDate\"]:\n",
    "            return \"Pending\"\n",
    "        else:\n",
    "            return \"Nothing\"\n",
    "    elif str(x[\"Status\"]) == \"Complete\":\n",
    "        if str(x[\"RumorDate\"]) != 'NaT' and x[\"ArrivalTime\"] >= x[\"RumorDate\"] and x[\"ArrivalTime\"] < x[\"AnnouncementDate\"]:\n",
    "            return \"Rumor\"\n",
    "        elif x[\"ArrivalTime\"] >= x[\"AnnouncementDate\"] and x[\"ArrivalTime\"] < x[\"ClosingDate\"]:\n",
    "            return \"Pending\"\n",
    "        elif x[\"ArrivalTime\"] >= x[\"ClosingDate\"]:\n",
    "            return \"Complete\"\n",
    "        else:\n",
    "            return \"Nothing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.65 s, sys: 34.5 ms, total: 2.68 s\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 12. define the new status based on the time\n",
    "final_df[\"NewStatus\"] = final_df.apply(lambda x: status_match(x), axis=1)\n",
    "final_df.drop([\"Status\", \"RumorDate\", \"AnnouncementDate\", \"ClosingDate\"], axis=1, inplace=True)\n",
    "final_df = final_df.sort_values([\"ArrivalTime\", \"Ticker_Source\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"jettrack_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1000 Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat((final_df[final_df[\"NewStatus\"] != \"Nothing\"], final_df[final_df[\"NewStatus\"] == \"Nothing\"].sample(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"jettrack_sample_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40944"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df.query(\"ArrivalTime > '2015-01-01'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nothing', 'Pending', 'Complete', 'Rumor'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.query(\"ArrivalTime > '2015-01-01' and ArrivalTime < '2017-01-01'\").NewStatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.query(\"ArrivalTime > '2015-01-01'\").to_csv(\"jettrack_new_shrinked.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
